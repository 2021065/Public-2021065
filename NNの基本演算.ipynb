{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "参考：https://ai-kenkyujo.com/programming/neuralnetworkpythonprogramming/"
      ],
      "metadata": {
        "id": "PhcEzvsnl4LG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCnVwgNSlKNL",
        "outputId": "25d03c5b-afaf-4e61-cb38-373d8df342ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14 32]\n"
          ]
        }
      ],
      "source": [
        "#numpyは線形代数学を扱うライブラリ\n",
        "import numpy as np\n",
        "#単純パーセプトロン\n",
        "#xは入力（層ではない）\n",
        "x = np.array([1, 2, 3])\n",
        "#wは重み\n",
        "w = np.array([[1, 4], [2, 5], [3, 6]])\n",
        "\n",
        "#yは出力結果\n",
        "y = np.dot(x, w)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numpyのimport\n",
        "import numpy as np\n",
        "\n",
        "#中間層と出力層（入力層を含めないで2層）の定義(define)\n",
        "def TwoLayer_Network():\n",
        " \n",
        " network={}\n",
        " \n",
        " #入力層と中間層(隠れ層)の重み\n",
        " network['W'] = np.array([[1,2],[3,4],[5,6]])\n",
        " #中間層（隠れ層）と出力層の重み\n",
        " network['V'] = np.array([[1,2,3],[4,5,6]])\n",
        " \n",
        " #バイアスとは偏りのことで、より精度を上げる手法である\n",
        " #バイアスの仕組みは、実際の人間脳細胞(ニューロン)にはない\n",
        "\n",
        " #入力層のバイアス\n",
        " network['b1']=np.array([1,2])\n",
        " #出力層のバイアス\n",
        " network['b2']=np.array([1,2,3]) \n",
        "\n",
        " return network\n",
        "\n",
        "#計算をするモデルの作成\n",
        "def forward(network,input_data):\n",
        " \n",
        " #W,Vに、上で設計した重みを代入する\n",
        " W,V = network['W'],network['V']\n",
        " #b1,b2に、上で設計したバイアスを代入する \n",
        " b1,b2 = network['b1'],network['b2']\n",
        " #入力層に対する重み付けの処理とバイアス\n",
        " Layer1 = np.dot(input_data,W) + b1\n",
        " #活性化関数はニューラルにおける発火の役割(入力を通すか通さないか等)\n",
        " #活性化関数（今回はシグモイド関数だが、CNNの中間層にはReLU関数を使うことが多い）\n",
        " Layer1 = sigmoid_function(Layer1)\n",
        " #中間層に対する重み付けの処理とバイアス\n",
        " Layer2 = np.dot(Layer1,V) + b2\n",
        " #重み付した中間層からの入力を「identity_function関数」へ入力し、output_dataに代入\n",
        " output_data = identity_function(Layer2)\n",
        " \n",
        " return output_data\n",
        " \n",
        "#シグモイド関数の定義\n",
        "def sigmoid_function(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#よくわからないけど、最終的な出力をここで決める？\n",
        "#今回は何も処理せずそのまま出力\n",
        "def identity_function(y):\n",
        "  return y\n",
        "#↑↑↑ここまでは必要なライブラリのインポートと関数・モデルの定義↑↑↑\n",
        "\n",
        "#↓↓↓ここからmain関数みたいな部分になる↓↓↓\n",
        "#モデルのインスタンス化(実体にする)\n",
        "network =TwoLayer_Network()\n",
        "#入力行列を定義\n",
        "input_data = np.array([1.0,0.5,1.0])\n",
        "#モデル、入力データを指定\n",
        "output_data = forward(network,input_data)\n",
        "\n",
        "#出力結果の表示\n",
        "print(output_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XcSr1Wml3j6",
        "outputId": "0651b9c9-a42c-4617-a15f-77f391b0dcc0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5.999772    8.99956243 11.99935285]\n"
          ]
        }
      ]
    }
  ]
}